{
  "optimizer": "Adam",
  "batch_size": 8, //8  ,  // Batch size per GPU. The effective batch size is effective_batch_size=world_size*batch_size
  "base_lr": 1e-3, // 1e-3,  // Will be multiplied by the effective_batch_size=world_size*batch_size.
  "max_lr": 1e-2, // 1e-2,  // Maximum resulting learning rate
  "gamma": 0.9955,  // Gamma of exponential learning rate scheduler
  "max_epoch": 20,
  "log_steps": 200,
  "checkpoint_epoch": 1,
  "checkpoints_to_keep": 5,  // outputs
  "logs_dirname": "logs",
  "checkpoints_dirname": "checkpoints"
}
